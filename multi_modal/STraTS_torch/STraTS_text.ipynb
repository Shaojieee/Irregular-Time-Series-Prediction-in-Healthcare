{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from data import load_mortality_dataset, pad_text_data\n",
    "from torch.utils.data import DataLoader\n",
    "from strats_text_model import load_Bert\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./mortality_mimic_3_benchmark/train_texts.pkl', 'rb') as f:\n",
    "    text = pickle.load(f)\n",
    "with open('./mortality_mimic_3_benchmark/train_text_times.pkl', 'rb') as f:\n",
    "    time = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14681"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14681"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at yikuan8/Clinical-Longformer were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "_, _, tokenizer = load_Bert(\n",
    "    text_encoder_model = 'bioLongformer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 179.60it/s]\n",
      "100it [00:00, 208.71it/s]\n",
      "100it [00:00, 222.33it/s]\n"
     ]
    }
   ],
   "source": [
    "train, val, test, V, D = load_mortality_dataset(\n",
    "    data_dir='./mortality_mimic_3_benchmark', \n",
    "    with_text=True, \n",
    "    tokenizer=tokenizer, \n",
    "    text_padding=True, \n",
    "    text_max_len=1024, \n",
    "    text_model='bioLongformer', \n",
    "    period_length=48, \n",
    "    num_notes=3,\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=2, collate_fn=pad_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaojieee/Desktop/fyp/multi_modal/STraTS_torch/data.py:635: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_text_times = pad_sequence([torch.tensor(time, dtype=torch.float) for time in X_text_times],batch_first=True,padding_value=0)\n",
      "/Users/shaojieee/Desktop/fyp/multi_modal/STraTS_torch/data.py:636: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_text_time_mask = pad_sequence([torch.tensor(time_mask, dtype=torch.long) for time_mask in X_text_time_mask],batch_first=True,padding_value=0)\n"
     ]
    }
   ],
   "source": [
    "X_demos, X_times, X_values, X_varis, Y, X_text_tokens, X_text_attention_mask, X_text_times, X_text_time_mask, X_text_feature_varis = iter(train_dataloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 500])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0667,  0.0667,  0.0667,  0.0667,  0.0667,  0.0667,  0.1500,  0.1500,\n",
       "          0.1500,  0.1500,  0.1500,  0.1500,  0.2333,  0.2333,  0.2333,  0.2333,\n",
       "          0.2333,  0.2333,  0.3167,  0.3167,  0.3167,  0.3167,  0.3167,  0.3167,\n",
       "          0.4000,  0.4000,  0.4000,  0.4000,  0.4000,  0.4000,  0.4833,  0.4833,\n",
       "          0.4833,  0.4833,  0.4833,  0.4833,  0.5167,  0.5167,  0.5167,  0.5167,\n",
       "          0.5167,  0.5167,  0.5667,  0.5667,  0.5667,  0.5667,  0.5667,  0.5667,\n",
       "          0.6500,  0.6500,  0.6500,  0.6500,  0.6500,  0.6500,  0.7333,  0.7333,\n",
       "          0.7333,  0.7333,  0.7333,  0.7333,  0.8167,  0.8167,  0.8167,  0.8167,\n",
       "          0.8167,  0.8167,  0.9000,  0.9000,  0.9000,  0.9000,  0.9000,  0.9000,\n",
       "          0.9833,  0.9833,  0.9833,  0.9833,  0.9833,  0.9833,  1.0667,  1.0667,\n",
       "          1.0667,  1.0667,  1.0667,  1.0667,  1.1500,  1.1500,  1.1500,  1.1500,\n",
       "          1.1500,  1.1500,  1.2333,  1.2333,  1.2333,  1.2333,  1.2333,  1.2333,\n",
       "          1.2333,  1.2333,  1.2333,  1.2333,  1.3167,  1.3167,  1.3167,  1.3167,\n",
       "          1.3167,  1.3167,  1.4000,  1.4000,  1.4000,  1.4000,  1.4000,  1.4000,\n",
       "          2.2333,  2.2333,  2.2333,  2.2333,  2.2333,  2.2333,  3.2333,  3.2333,\n",
       "          3.2333,  3.2333,  3.2333,  3.2333,  3.2333,  3.7333,  3.7333,  3.7333,\n",
       "          3.7333,  3.7333,  3.7333,  3.9833,  3.9833,  3.9833,  3.9833,  3.9833,\n",
       "          4.2333,  4.2333,  4.2333,  4.2333,  4.2333,  4.8167,  4.8167,  4.8167,\n",
       "          4.8167,  4.8167,  4.9000,  4.9000,  4.9000,  4.9000,  4.9000,  5.0667,\n",
       "          5.0667,  5.0667,  5.0667,  5.0667,  5.1500,  5.1500,  5.1500,  5.1500,\n",
       "          5.1500,  5.2333,  5.2333,  5.2333,  5.2333,  5.2333,  5.2333,  5.2333,\n",
       "          5.2333,  5.2333,  5.2333,  5.2333,  5.2667,  5.3667,  5.3667,  5.3667,\n",
       "          5.6000,  6.8333,  6.8333,  7.7167,  7.7167,  7.7167,  8.4000,  8.4000,\n",
       "          9.0833,  9.0833,  9.9500,  9.9500, 10.4833, 10.7000, 11.8167, 11.8167,\n",
       "         11.8167, 11.8167, 11.8167, 11.8167, 11.8167, 11.9000, 11.9000, 11.9000,\n",
       "         11.9000, 11.9000, 11.9833, 11.9833, 11.9833, 11.9833, 11.9833, 12.0667,\n",
       "         12.0667, 12.0667, 12.0667, 12.0667, 12.1500, 12.1500, 12.1500, 12.1500,\n",
       "         12.2333, 12.2333, 12.2333, 12.2333, 12.2333, 12.2333, 12.2667, 12.2667,\n",
       "         12.3167, 12.3167, 12.3167, 12.3167, 12.3167, 12.3833, 12.4833, 12.4833,\n",
       "         12.4833, 12.4833, 12.4833, 12.7333, 12.7333, 12.7333, 12.7333, 12.7333,\n",
       "         12.9833, 12.9833, 12.9833, 12.9833, 12.9833, 12.9833, 12.9833, 12.9833,\n",
       "         13.2333, 13.2333, 13.2333, 13.2333, 13.2333, 13.2333, 13.2333, 13.2333,\n",
       "         13.2333, 13.4833, 13.4833, 13.4833, 13.4833, 13.4833, 13.5667, 13.5667,\n",
       "         13.5667, 13.5667, 13.5667, 13.6500, 13.6500, 13.6500, 13.6500, 13.6500,\n",
       "         13.7333, 13.7333, 13.7333, 13.7333, 13.7333, 13.8167, 13.8167, 13.8167,\n",
       "         13.8167, 13.8167, 13.9000, 13.9000, 13.9000, 13.9000, 13.9000, 13.9833,\n",
       "         13.9833, 13.9833, 13.9833, 13.9833, 14.0667, 14.0667, 14.0667, 14.0667,\n",
       "         14.0667, 14.2333, 14.2333, 14.2333, 14.2333, 14.2333, 14.2333, 14.2333,\n",
       "         14.2333, 14.2333, 14.2333, 14.7333, 14.7333, 14.7333, 14.7333, 14.7333,\n",
       "         14.7333, 15.2333, 15.2333, 15.2333, 15.2333, 15.2333, 15.2333, 15.2500,\n",
       "         15.2833, 15.2833, 15.7333, 15.7333, 15.7333, 15.7333, 15.7333, 15.7333,\n",
       "         16.2333, 16.2333, 16.2333, 16.2333, 16.2333, 16.2333, 16.2333, 16.5333,\n",
       "         16.5333, 17.2333, 17.2333, 17.2333, 17.2333, 17.2333, 17.2333, 17.2333,\n",
       "         17.2333, 17.2333, 17.2333, 18.2333, 18.2333, 18.2333, 18.2333, 18.2333,\n",
       "         18.2333, 18.2333, 18.2333, 18.2333, 18.2333, 19.2333, 19.2333, 19.2333,\n",
       "         19.2333, 19.2333, 19.2333, 19.5167, 19.5167, 19.5333, 19.7333, 19.7333,\n",
       "         19.7333, 19.7333, 19.7333, 19.7333, 20.2333, 20.2333, 20.2333, 20.2333,\n",
       "         20.2333, 20.2333, 20.2333, 20.2333, 20.2333, 20.2333, 20.2333, 20.2333,\n",
       "         20.7333, 20.7333, 20.7333, 20.7333, 20.7333, 20.7333, 20.7333, 20.8833,\n",
       "         20.8833, 20.8833, 21.2333, 21.2333, 21.2333, 21.2333, 21.2333, 21.2333,\n",
       "         21.2333, 21.2333, 21.2333, 21.2333, 21.2333, 21.2333, 22.2333, 22.2333,\n",
       "         22.2333, 22.2333, 22.2333, 22.2333, 22.2333, 23.2167, 23.2333, 23.2333,\n",
       "         23.2333, 23.2333, 23.2333, 23.2333, 23.6500, 23.6500, 23.6500, 23.7333,\n",
       "         23.7333, 23.7333, 23.7333, 23.7333, 23.7333, 24.2333, 24.2333, 24.2333,\n",
       "         24.2333, 24.2333, 24.2333, 24.2333, 24.2333, 24.2333, 24.2333, 24.2333,\n",
       "         24.2833, 24.4833, 24.4833, 24.4833, 24.4833, 24.4833, 24.4833, 24.4833,\n",
       "         24.7333, 24.7333, 24.7333, 24.7333, 24.7333, 24.7333, 24.7333, 24.9833,\n",
       "         24.9833, 24.9833, 24.9833, 24.9833, 24.9833, 24.9833, 25.2333, 25.2333,\n",
       "         25.2333, 25.2333, 25.2333, 25.2333, 25.2333, 25.2333, 25.2333, 25.2333,\n",
       "         25.2333, 25.6500, 25.6500, 25.9833, 26.2333, 26.2333, 26.2333, 26.2333,\n",
       "         26.2333, 26.2333, 26.2333, 27.2333, 27.2333, 27.2333, 27.2333, 27.2333,\n",
       "         27.2333, 27.2333, 27.7333, 27.7333, 27.7333, 27.7333, 27.7333, 27.7333,\n",
       "         27.7333, 28.2333, 28.2333, 28.2333],\n",
       "        [ 0.6672,  0.6672,  0.6672,  0.6672,  0.6672,  0.6672,  0.6672,  0.6672,\n",
       "          0.6672,  0.6672,  0.6672,  0.6672,  0.9172,  1.1672,  1.1672,  1.1672,\n",
       "          1.1672,  1.1672,  1.1672,  2.1672,  2.1672,  2.1672,  2.1672,  2.1672,\n",
       "          2.1672,  2.1672,  3.1672,  3.1672,  3.1672,  3.1672,  3.1672,  3.1672,\n",
       "          3.1672,  3.5839,  3.5839,  3.5839,  3.5839,  3.5839,  3.5839,  4.1672,\n",
       "          4.1672,  4.1672,  4.1672,  4.1672,  4.1672,  4.1672,  5.1672,  5.1672,\n",
       "          5.1672,  5.1672,  5.1672,  5.1672,  5.1672,  5.1672,  5.1672,  5.1672,\n",
       "          5.1672,  6.1672,  6.1672,  6.1672,  6.1672,  6.1672,  6.1672,  7.1672,\n",
       "          7.1672,  7.1672,  7.1672,  7.1672,  7.1672,  7.1672,  7.3172,  8.1672,\n",
       "          8.1672,  8.1672,  8.1672,  8.1672,  8.1672,  9.1672,  9.1672,  9.1672,\n",
       "          9.1672,  9.1672,  9.1672,  9.1672,  9.1672,  9.1672,  9.1672,  9.1672,\n",
       "          9.1672, 10.1672, 10.1672, 10.1672, 10.1672, 10.1672, 10.1672, 11.1672,\n",
       "         11.1672, 11.1672, 11.1672, 11.1672, 11.1672, 12.1672, 12.1672, 12.1672,\n",
       "         12.1672, 12.1672, 12.1672, 13.1672, 13.1672, 13.1672, 13.1672, 13.1672,\n",
       "         13.1672, 13.1672, 13.1672, 13.1672, 13.1672, 13.1672, 21.1672, 21.1672,\n",
       "         21.1672, 21.1672, 21.1672, 21.1672, 21.1672, 21.1672, 21.1672, 21.1672,\n",
       "         21.1672, 22.1672, 22.1672, 22.1672, 22.1672, 22.1672, 22.1672, 22.6672,\n",
       "         23.0006, 25.1672, 25.1672, 25.1672, 25.1672, 25.1672, 25.1672, 25.1672,\n",
       "         25.1672, 25.1672, 25.1672, 25.1672, 26.1672, 26.1672, 26.1672, 26.1672,\n",
       "         26.1672, 26.1672, 27.1672, 27.1672, 27.1672, 27.1672, 27.1672, 27.1672,\n",
       "         27.1672, 28.1672, 28.1672, 28.1672, 28.1672, 28.1672, 28.1672, 29.1672,\n",
       "         29.1672, 29.1672, 29.1672, 29.1672, 29.1672, 29.1672, 29.1672, 29.1672,\n",
       "         29.1672, 29.1672, 31.1672, 31.1672, 31.1672, 31.1672, 31.1672, 31.1672,\n",
       "         33.1672, 33.1672, 33.1672, 33.1672, 33.1672, 33.1672, 33.1672, 33.7006,\n",
       "         34.1672, 34.1672, 35.1672, 35.1672, 35.1672, 35.1672, 35.1672, 35.1672,\n",
       "         35.1672, 35.1672, 35.1672, 35.1672, 37.1672, 37.1672, 37.1672, 37.1672,\n",
       "         37.1672, 37.1672, 37.1672, 37.1672, 37.1672, 37.1672, 37.1672, 39.1672,\n",
       "         39.1672, 39.1672, 39.1672, 39.1672, 39.1672, 41.1672, 41.1672, 41.1672,\n",
       "         41.1672, 41.1672, 41.1672, 41.1672, 41.1672, 41.1672, 41.1672, 41.1672,\n",
       "         41.1672, 43.1672, 43.1672, 43.1672, 43.1672, 43.1672, 43.1672, 45.1672,\n",
       "         45.1672, 45.1672, 45.1672, 45.1672, 45.1672, 45.1672, 45.1672, 45.1672,\n",
       "         45.1672, 46.1672, 47.1672, 47.1672, 47.1672, 47.1672, 47.1672, 47.1672,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [22.6000, 34.8167, 46.1333]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1024])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_feature_varis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 500])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_varis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1024])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    0,     0,     0,  ...,     0,     0,     0],\n",
       "         [    0,     0,     0,  ...,     0,     0,     0],\n",
       "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
       "\n",
       "        [[    0,   282, 35857,  ...,     1,     1,     1],\n",
       "         [    0,    90,    73,  ...,     1,     1,     1],\n",
       "         [    0,  7048,   575,  ...,     1,     1,     1]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test, V, D = load_mortality_dataset(\n",
    "    data_dir='./mortality_mimic_3_benchmark', \n",
    "    with_text=False, \n",
    "    period_length=48, \n",
    "    debug=False\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at yikuan8/Clinical-Longformer were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.weight', 'longformer.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from model import STraTS\n",
    "\n",
    "text_model, config, tokenizer = load_Bert(\n",
    "    text_encoder_model = 'bioLongformer'\n",
    ")\n",
    "\n",
    "model = STraTS(\n",
    "    D=D, # No. of static variables\n",
    "    V=V+1, # No. of variables / features\n",
    "    d=64, # Input size of attention layer\n",
    "    N=2, # No. of Encoder blocks\n",
    "    he=4, # No. of heads in multi headed encoder blocks\n",
    "    dropout=0, \n",
    "    with_text=False,\n",
    "    forecast=False, \n",
    "    return_embeddings=False,\n",
    "    combine_feature_value_encoding=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaojieee/.pyenv/versions/3.8.16/envs/fyp/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "from utils import mortality_loss\n",
    "loss_fn = mortality_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "User specified an unsupported autocast device_type 'mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, optimizer, train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/fyp/lib/python3.8/site-packages/accelerate/accelerator.py:1213\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1211\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_megatron_lm(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1213\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_one(obj, device_placement\u001b[38;5;241m=\u001b[39md) \u001b[38;5;28;01mfor\u001b[39;00m obj, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, device_placement))\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tpu_should_fix_optimizer \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixed_precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp8\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;66;03m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/fyp/lib/python3.8/site-packages/accelerate/accelerator.py:1214\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1211\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_megatron_lm(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1213\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m-> 1214\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m obj, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, device_placement)\n\u001b[1;32m   1215\u001b[0m     )\n\u001b[1;32m   1216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_one(obj, device_placement\u001b[38;5;241m=\u001b[39md) \u001b[38;5;28;01mfor\u001b[39;00m obj, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, device_placement))\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tpu_should_fix_optimizer \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixed_precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp8\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;66;03m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/fyp/lib/python3.8/site-packages/accelerate/accelerator.py:1094\u001b[0m, in \u001b[0;36mAccelerator._prepare_one\u001b[0;34m(self, obj, first_pass, device_placement)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_data_loader(obj, device_placement\u001b[38;5;241m=\u001b[39mdevice_placement)\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m-> 1094\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_placement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer):\n\u001b[1;32m   1096\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_optimizer(obj, device_placement\u001b[38;5;241m=\u001b[39mdevice_placement)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/fyp/lib/python3.8/site-packages/accelerate/accelerator.py:1280\u001b[0m, in \u001b[0;36mAccelerator.prepare_model\u001b[0;34m(self, model, device_placement, evaluation_mode)\u001b[0m\n\u001b[1;32m   1278\u001b[0m model\u001b[38;5;241m.\u001b[39m_original_forward \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward\n\u001b[1;32m   1279\u001b[0m model_forward_func \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model\u001b[38;5;241m.\u001b[39mforward, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__func__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mforward\n\u001b[0;32m-> 1280\u001b[0m autocast_context \u001b[38;5;241m=\u001b[39m \u001b[43mget_mixed_precision_context_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnative_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocast_handler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1281\u001b[0m new_forward \u001b[38;5;241m=\u001b[39m autocast_context(model_forward_func)\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model\u001b[38;5;241m.\u001b[39mforward, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__func__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/fyp/lib/python3.8/site-packages/accelerate/utils/modeling.py:1534\u001b[0m, in \u001b[0;36mget_mixed_precision_context_manager\u001b[0;34m(native_amp, autocast_kwargs)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m native_amp:\n\u001b[1;32m   1533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmixed_precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1534\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mautocast_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmixed_precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbf16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m   1536\u001b[0m         DistributedType\u001b[38;5;241m.\u001b[39mNO,\n\u001b[1;32m   1537\u001b[0m         DistributedType\u001b[38;5;241m.\u001b[39mMULTI_CPU,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         DistributedType\u001b[38;5;241m.\u001b[39mFSDP,\n\u001b[1;32m   1542\u001b[0m     ]:\n\u001b[1;32m   1543\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39mstate\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mautocast_kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/fyp/lib/python3.8/site-packages/torch/amp/autocast_mode.py:241\u001b[0m, in \u001b[0;36mautocast.__init__\u001b[0;34m(self, device_type, dtype, enabled, cache_enabled)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfast_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_device_mod\u001b[38;5;241m.\u001b[39mget_autocast_dtype()\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser specified an unsupported autocast device_type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    246\u001b[0m     enabled\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mcommon\u001b[38;5;241m.\u001b[39mamp_definitely_not_available()\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m ):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: User specified an unsupported autocast device_type 'mps'"
     ]
    }
   ],
   "source": [
    "model, optimizer, train_dataloader = accelerator.prepare(model, optimizer, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [01:13<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for batch in tqdm(train_dataloader):\n",
    "    X_demos, X_times, X_values, X_varis, Y = batch\n",
    "    Y_pred = model(X_demos, X_times, X_values, X_varis)\n",
    "\n",
    "    loss = loss_fn(Y, Y_pred)\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaojieee/Desktop/fyp/multi_modal/STraTS_torch/data.py:635: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_text_times = pad_sequence([torch.tensor(time, dtype=torch.float) for time in X_text_times],batch_first=True,padding_value=0)\n",
      "/Users/shaojieee/Desktop/fyp/multi_modal/STraTS_torch/data.py:636: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_text_time_mask = pad_sequence([torch.tensor(time_mask, dtype=torch.long) for time_mask in X_text_time_mask],batch_first=True,padding_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_varis_emb: torch.Size([2, 500, 64])\n",
      "ts_values_emb: torch.Size([2, 500, 64])\n",
      "ts_times_emb: torch.Size([2, 500, 64])\n",
      "text_varis_emb: torch.Size([2, 3, 64])\n",
      "text_values_emb: torch.Size([2, 3, 768])\n",
      "text_values_emb: torch.Size([2, 3, 64])\n",
      "text_times_emb: torch.Size([2, 3, 64])\n",
      "comb_emb: torch.Size([2, 503, 64])\n",
      "Mask: torch.Size([2, 503])\n",
      "cont_emb: torch.Size([2, 503, 64])\n",
      "attn_weights: torch.Size([2, 503, 1])\n",
      "fused_emb: torch.Size([2, 64])\n",
      "conc: torch.Size([2, 64])\n"
     ]
    }
   ],
   "source": [
    "X_demos, X_times, X_values, X_varis, Y, X_text_tokens, X_text_attention_mask, X_text_times, X_text_time_mask, X_text_feature_varis = iter(train_dataloader).next()\n",
    "Y_pred = model(X_demos, X_times, X_values, X_varis, X_text_tokens, X_text_attention_mask, X_text_times, X_text_feature_varis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7271, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(Y, Y_pred)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5754, 0.5941], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
