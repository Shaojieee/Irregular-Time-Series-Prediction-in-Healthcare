{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa56515-014b-4290-98f2-f36a88d10670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Module containing utility functions specific to implementing models.\"\"\"\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "K = tf.keras.backend\n",
    "\n",
    "\n",
    "def build_and_compute_output_shape(layer, input_shape):\n",
    "    layer.build(input_shape)\n",
    "    return layer.compute_output_shape(input_shape)\n",
    "\n",
    "\n",
    "class ResNetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, bottleneck, **kwargs):\n",
    "        super.__init__(**kwargs)\n",
    "        self.bottleneck = bottleneck\n",
    "        self.layer1 = tf.keras.layers.Dense(bottleneck, activation='relu')\n",
    "        self.layer2 = None\n",
    "        self.bn = tf.keras.layers.BatchNormalization(bottleneck)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        layer1_out = build_and_compute_output_shape(self.layer1, input_shape)\n",
    "        bn_out = build_and_compute_output_shape(self.bn, layer1_out)\n",
    "        layer2_out = build_and_compute_output_shape(self.layer2, bn_out)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def build_mask(data, lengths):\n",
    "    \"\"\"Create mask for data tensor according to lengths.\"\"\"\n",
    "    mask = tf.sequence_mask(lengths, maxlen=tf.shape(data)[1], dtype=tf.int32,\n",
    "                            name='mask')\n",
    "    return mask\n",
    "\n",
    "\n",
    "# pylint: disable=missing-docstring\n",
    "def mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    first_log = tf.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = tf.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return tf.reduce_mean(\n",
    "        tf.squared_difference(first_log, second_log), axis=-1)\n",
    "\n",
    "\n",
    "def mask_observations(data, mask):\n",
    "    \"\"\"Mask invalid observations of data using masking tensor.\n",
    "\n",
    "    Args:\n",
    "        data: tensor (bs x observations x ...) to mask\n",
    "        lengths: Masking tensor\n",
    "    Returns:\n",
    "        Masked tensor\n",
    "\n",
    "    \"\"\"\n",
    "    # Expand dimensionality to allow broadcasing\n",
    "    dims_to_add = len(data.get_shape()) - len(mask.get_shape())\n",
    "    for i in range(dims_to_add):\n",
    "        mask = tf.expand_dims(mask, -1)\n",
    "    masked_data = data * tf.cast(mask, tf.float32)\n",
    "    return masked_data\n",
    "\n",
    "\n",
    "def segment_softmax(data, segment_ids, eps=1e-7):\n",
    "    \"\"\"Compute numerically stable softmax accroding to segments.\n",
    "\n",
    "    Computes the softmax along the last axis of data, while grouping values\n",
    "    according to their segment ids.\n",
    "\n",
    "    Args:\n",
    "        data:\n",
    "        segment_ids:\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    # For numerical stability subtract the max from data values\n",
    "    max_values = tf.math.segment_max(data, segment_ids)\n",
    "    max_values = tf.gather_nd(max_values, tf.expand_dims(segment_ids, -1))\n",
    "    max_values = tf.stop_gradient(max_values)\n",
    "    normalized = data - max_values\n",
    "\n",
    "    numerator = tf.exp(normalized)\n",
    "    denominator = tf.math.segment_sum(numerator, segment_ids)\n",
    "    denominator = tf.gather_nd(denominator, tf.expand_dims(segment_ids, -1))\n",
    "\n",
    "    # Use this to avoid problems when computing the softmax, we sometime got\n",
    "    # NaNs due to division by zero. If that occurs simply replace output with\n",
    "    # zero instead of NaN.\n",
    "    softmax = numerator / (denominator + eps)\n",
    "    return softmax\n",
    "\n",
    "\n",
    "def training_placeholder():\n",
    "    \"\"\"Either gets or creates the boolean placeholder `is_training`.\n",
    "\n",
    "    The placeholder is initialized to have a default value of False,\n",
    "    indicating that training is not taking place.\n",
    "    Thus it is required to pass True to the placeholder\n",
    "    to indicate training being active.\n",
    "\n",
    "    Returns:\n",
    "        tf.placeholder_with_default(False, name='is_training')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        training = tf.get_default_graph().get_tensor_by_name('is_training:0')\n",
    "    except KeyError:\n",
    "        # We need to set this variable scope, otherwise the name of the\n",
    "        # placeholder would be dependent on the variable scope of the caller\n",
    "        cur_scope = tf.get_variable_scope().name\n",
    "        if cur_scope == '':\n",
    "            training = tf.placeholder_with_default(\n",
    "                False, name='is_training', shape=[])\n",
    "        else:\n",
    "            with tf.variable_scope('/'):\n",
    "                training = tf.placeholder_with_default(\n",
    "                    False, name='is_training', shape=[])\n",
    "    return training\n",
    "\n",
    "\n",
    "def add_scope(fn):\n",
    "    \"\"\"Decorate method by wrapping it into a tensorflow name scope.\"\"\"\n",
    "    fn_name = fn.__name__\n",
    "    if fn_name.startswith('_'):\n",
    "        fn_name = fn_name[1:]\n",
    "\n",
    "    def wrapped_fn(self, *args, **kwargs):\n",
    "        # Start with a '/' to indicate absolute address\n",
    "        class_name_scope = self.name\n",
    "        function_name_scope = fn_name.replace('_', '-')\n",
    "        with tf.name_scope(None):\n",
    "            with tf.name_scope(class_name_scope+function_name_scope):\n",
    "                return fn(self, *args, **kwargs)\n",
    "    return wrapped_fn\n",
    "\n",
    "\n",
    "def normalized_l2_regularizer(scale, scope=None):\n",
    "    \"\"\"Return a function that applys L2 regularization to weights.\n",
    "\n",
    "    This implementation returns the average l2 norm (per weight) and thus\n",
    "    allows defining the degree of regularization indepedent of the layer sizes.\n",
    "\n",
    "    Args:\n",
    "      scale: A scalar multiplier `Tensor`. 0.0 disables the regularizer.\n",
    "      scope: An optional scope name.\n",
    "    Returns:\n",
    "      A function with signature `l2(weights)` that applies L2 regularization.\n",
    "\n",
    "    \"\"\"\n",
    "    if scale < 0.:\n",
    "        raise ValueError('Setting a scale less than 0 on a regularizer: %g.' %\n",
    "                         scale)\n",
    "    if scale == 0.:\n",
    "        logging.info('Scale of 0 disables regularizer.')\n",
    "        return lambda _: None\n",
    "\n",
    "    def l2(weights):\n",
    "        \"\"\"Apply l2 regularization to weights.\"\"\"\n",
    "        with tf.name_scope(scope, 'norm_l2_regularizer', [weights]) as name:\n",
    "            my_scale = tf.convert_to_tensor(scale,\n",
    "                                            dtype=weights.dtype.base_dtype,\n",
    "                                            name='scale')\n",
    "            size_of_tensor = tf.cast(\n",
    "                tf.reduce_prod(tf.shape(weights)),\n",
    "                weights.dtype.base_dtype\n",
    "            )\n",
    "            return tf.multiply(\n",
    "                my_scale,\n",
    "                tf.nn.l2_loss(weights) / size_of_tensor,\n",
    "                name=name\n",
    "            )\n",
    "\n",
    "    return l2\n",
    "\n",
    "\n",
    "def pad_and_expand(tensor, maxlen):\n",
    "    \"\"\"Pad 1D tensor along last dim and add zeroth dimension for stacking.\"\"\"\n",
    "    padding_length = maxlen - tf.shape(tensor)[-1]\n",
    "    padded = tf.pad(tensor, [[0, padding_length]])\n",
    "    return tf.expand_dims(padded, axis=0)\n",
    "\n",
    "\n",
    "def pad_and_expand2D(tensor, maxlen):\n",
    "    \"\"\"Pad 2D tensor along first dim and add zeroth dimension for stacking.\"\"\"\n",
    "    padding_length = maxlen - tf.shape(tensor)[0]\n",
    "    padded = tf.pad(tensor, [[0, padding_length], [0, 0]])\n",
    "    return tf.expand_dims(padded, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6523b346-f23f-4126-a082-905985f55f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "class PaddedToSegments(tf.keras.layers.Layer):\n",
    "    \"\"\"Convert a padded tensor with mask to a stacked tensor with segments.\"\"\"\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, input_shape[-1])\n",
    "\n",
    "    def call(self, inputs, mask):\n",
    "        valid_observations = tf.where(mask)\n",
    "        collected_values = tf.gather_nd(inputs, valid_observations)\n",
    "        return collected_values, valid_observations[:, 0]\n",
    "\n",
    "\n",
    "def cumulative_softmax_weighting(values, preattention, segment_ids, eps=1e-7):\n",
    "    \"\"\"Cumulative softmax weighting of values.\n",
    "\n",
    "    Args:\n",
    "        values: Values expected shape [n_samples, feature_dim]\n",
    "        preattention: Preattention values, expected shape [n_samples, n_heads]\n",
    "        segment_ids: Segment ids\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    head_preattn = tf.unstack(preattention, axis=-1)\n",
    "    exp_head_preattn = []\n",
    "    cumulative_exp_preattn = []\n",
    "\n",
    "    for cur_head_preattn in head_preattn:\n",
    "        # For numerical stability subtract the max from data values\n",
    "        max_values = tf.math.segment_max(cur_head_preattn, segment_ids)\n",
    "        max_values = tf.gather_nd(max_values, tf.expand_dims(segment_ids, -1))\n",
    "        max_values = tf.stop_gradient(max_values)\n",
    "\n",
    "        normalized = cur_head_preattn - max_values\n",
    "        exp_preattn = tf.exp(normalized, name='exp_preattn')\n",
    "        exp_head_preattn.append(exp_preattn)\n",
    "        cumulative_exp_preattn.append(\n",
    "            cumulative_segment_sum(\n",
    "                exp_preattn, segment_ids, name='segment_cumsum'))\n",
    "\n",
    "    exp_head_preattn = tf.stack(exp_head_preattn, -1)\n",
    "    weighted_values = \\\n",
    "        tf.expand_dims(values, 1) * tf.expand_dims(exp_head_preattn, -1)\n",
    "\n",
    "    cumulative_exp_preattn = tf.stack(cumulative_exp_preattn, axis=-1)\n",
    "\n",
    "    # Sum the values\n",
    "    out = (\n",
    "        (cumulative_segment_sum(weighted_values, segment_ids) + eps)\n",
    "        / (tf.expand_dims(cumulative_exp_preattn, -1) + eps)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def cumulative_segment_wrapper(fun):\n",
    "    \"\"\"Wrap a cumulative function such that it can be applied to segments.\n",
    "\n",
    "    Args:\n",
    "        fun: The cumulative function\n",
    "\n",
    "    Returns:\n",
    "        Wrapped function.\n",
    "\n",
    "    \"\"\"\n",
    "    def wrapped_segment_op(x, segment_ids, **kwargs):\n",
    "        with tf.compat.v1.name_scope(\n",
    "                None, default_name=fun.__name__+'_segment_wrapper', values=[x]):\n",
    "            segments, _ = tf.unique(segment_ids)\n",
    "            n_segments = tf.shape(segments)[0]\n",
    "            output_array = tf.TensorArray(\n",
    "                x.dtype, size=n_segments, infer_shape=False)\n",
    "\n",
    "            def loop_cond(i, out):\n",
    "                return i < n_segments\n",
    "\n",
    "            def execute_cumulative_op_on_segment(i, out):\n",
    "                segment_indices = tf.where(tf.equal(segment_ids, segments[i]))\n",
    "                seg_begin = tf.reduce_min(segment_indices)\n",
    "                seg_end = tf.reduce_max(segment_indices)\n",
    "                segment_data = x[seg_begin:seg_end+1]\n",
    "                out = out.write(i, fun(segment_data, **kwargs))\n",
    "                return i+1, out\n",
    "\n",
    "            i_end, filled_array = tf.while_loop(\n",
    "                loop_cond,\n",
    "                execute_cumulative_op_on_segment,\n",
    "                loop_vars=(tf.constant(0), output_array),\n",
    "                parallel_iterations=10,\n",
    "                swap_memory=True\n",
    "            )\n",
    "            output_tensor = filled_array.concat()\n",
    "            output_tensor.set_shape(x.get_shape())\n",
    "            return output_tensor\n",
    "\n",
    "    return wrapped_segment_op\n",
    "\n",
    "\n",
    "def cumulative_mean(tensor):\n",
    "    \"\"\"Cumulative mean of a rank 2 tensor.\n",
    "\n",
    "    Args:\n",
    "        tensor: Input tensor\n",
    "\n",
    "    Returns:\n",
    "        Tensor with same shape as input but containing cumulative mean.\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(tensor.shape) == 2\n",
    "    n_elements = tf.cast(tf.shape(tensor)[0], tensor.dtype)\n",
    "    start = tf.constant(1, dtype=tensor.dtype)\n",
    "    n_elements_summed = tf.range(start, n_elements+1, dtype=tensor.dtype)\n",
    "    return tf.cumsum(tensor, axis=0) / tf.expand_dims(n_elements_summed, -1)\n",
    "\n",
    "\n",
    "cumulative_segment_mean = cumulative_segment_wrapper(cumulative_mean)\n",
    "cumulative_segment_sum = cumulative_segment_wrapper(tf.math.cumsum)\n",
    "\n",
    "\n",
    "def cumulative_softmax(tensor):\n",
    "    \"\"\"Cumulative softmax operation\n",
    "\n",
    "    Args:\n",
    "        tensor: 2d tensor\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    assert len(tensor.shape) == 1\n",
    "    max_values = tf.reduce_max(tensor, axis=0)\n",
    "    normalized = tensor - max_values\n",
    "\n",
    "    numerator = tf.exp(normalized)\n",
    "    denominator = tf.cumsum(numerator, axis=0)\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "class SegmentLayerNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon=1e-5, **kwargs):\n",
    "        self.epsilon = epsilon\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['epsilon'] = self.epsilon\n",
    "        return config\n",
    "\n",
    "    # noinspection PyAttributeOutsideInit\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[-1]\n",
    "        self.gain = self.add_weight(\n",
    "            name='gain',\n",
    "            shape=(dim,),\n",
    "            initializer='ones',\n",
    "            trainable=True)\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias',\n",
    "            shape=(dim,),\n",
    "            initializer='zeros',\n",
    "            trainable=True)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, segment_ids, **kwargs):\n",
    "        # Get one mean per instance\n",
    "        segments, _, count = tf.unique_with_counts(segment_ids)\n",
    "        divisor = tf.cast(count * inputs.get_shape()[-1], tf.float32)\n",
    "        mean = tf.reduce_sum(\n",
    "            tf.math.segment_sum(inputs, segment_ids),\n",
    "            axis=-1\n",
    "        ) / divisor\n",
    "        mean = tf.gather(mean, segment_ids, axis=-1)[:, None]\n",
    "\n",
    "        variance = tf.reduce_sum(\n",
    "            tf.math.segment_sum((inputs - mean) ** 2, segment_ids),\n",
    "            axis=-1\n",
    "        ) / divisor\n",
    "        variance = tf.gather(variance, segment_ids, axis=-1)[:, None]\n",
    "\n",
    "        epsilon = tf.constant(self.epsilon, dtype=tf.float32)\n",
    "        normalized_inputs = (inputs - mean) / tf.math.sqrt(variance + epsilon)\n",
    "        result = self.gain * normalized_inputs + self.bias\n",
    "        return result\n",
    "\n",
    "\n",
    "class LayerNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, axis=-1, epsilon=1e-5, **kwargs):\n",
    "        self.axis = axis\n",
    "        self.epsilon = epsilon\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['axis'] = self.axis\n",
    "        config['epsilon'] = self.epsilon\n",
    "        return config\n",
    "\n",
    "    # noinspection PyAttributeOutsideInit\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[-1]\n",
    "        self.gain = self.add_weight(\n",
    "            name='gain',\n",
    "            shape=(dim,),\n",
    "            initializer='ones',\n",
    "            trainable=True)\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias',\n",
    "            shape=(dim,),\n",
    "            initializer='zeros',\n",
    "            trainable=True)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        mean = tf.reduce_mean(inputs, axis=self.axis, keepdims=True)\n",
    "        variance = tf.reduce_mean(\n",
    "            (inputs - mean) ** 2, axis=self.axis, keepdims=True)\n",
    "        epsilon = tf.constant(self.epsilon, dtype=tf.float32)\n",
    "        normalized_inputs = (inputs - mean) / tf.sqrt(variance + epsilon)\n",
    "        result = self.gain * normalized_inputs + self.bias\n",
    "        return result\n",
    "\n",
    "\n",
    "class SegmentAggregation(tf.keras.layers.Layer):\n",
    "    def __init__(self, aggregation_fn='sum', cumulative=False):\n",
    "        super().__init__()\n",
    "        self.cumulative = cumulative\n",
    "        self.aggregation_fn = self._get_aggregation_fn(aggregation_fn)\n",
    "\n",
    "    def _get_aggregation_fn(self, aggregation_fn):\n",
    "        if not self.cumulative:\n",
    "            if aggregation_fn == 'sum':\n",
    "                return tf.math.segment_sum\n",
    "            elif aggregation_fn == 'mean':\n",
    "                return tf.math.segment_mean\n",
    "            elif aggregation_fn == 'max':\n",
    "                return tf.math.segment_max\n",
    "            else:\n",
    "                raise ValueError('Invalid aggregation function')\n",
    "        else:\n",
    "            if aggregation_fn == 'sum':\n",
    "                return cumulative_segment_wrapper(tf.math.cumsum)\n",
    "            elif aggregation_fn == 'mean':\n",
    "                return cumulative_segment_wrapper(cumulative_mean)\n",
    "            elif aggregation_fn == 'max':\n",
    "                raise ValueError('max aggregation function not supported with cumulative aggregation.')\n",
    "            else:\n",
    "                raise ValueError('Invalid aggregation function')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def call(self, data, segment_ids):\n",
    "        assert segment_ids is not None\n",
    "        return self.aggregation_fn(data, segment_ids)\n",
    "\n",
    "\n",
    "class MySequential(tf.keras.layers.Layer):\n",
    "    \"\"\"Simplified version of tf.keras.Sequential, supports segment_ids.\"\"\"\n",
    "\n",
    "    def __init__(self, layers, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layers = []\n",
    "        for layer in layers:\n",
    "            self.add(layer)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        last_shape = input_shape\n",
    "        for layer in self.layers:\n",
    "            last_shape = layer.compute_output_shape(last_shape)\n",
    "        return last_shape\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        last_shape = input_shape\n",
    "        for layer in self.layers:\n",
    "            layer.build(last_shape)\n",
    "            last_shape = layer.compute_output_shape(last_shape)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def add(self, layer):\n",
    "        next_layer_index = len(self.layers)\n",
    "        layer_name = f'{next_layer_index}_{layer.name}'\n",
    "        self.layers.append(layer)\n",
    "        setattr(self, layer_name, layer)\n",
    "        self.built = False\n",
    "\n",
    "    def call(self, inputs, segment_ids):\n",
    "        outputs = inputs  # handle the corner case where self.layers is empty\n",
    "        for layer in self.layers:\n",
    "            # During each iteration, `inputs` are the inputs to `layer`, and `outputs`\n",
    "            # are the outputs of `layer` applied to `inputs`. At the end of each\n",
    "            # iteration `inputs` is set to `outputs` to prepare for the next layer.\n",
    "            kwargs = {}\n",
    "            argspec = inspect.getargspec(layer.call)\n",
    "            if 'segment_ids' in argspec.args:\n",
    "                kwargs['segment_ids'] = segment_ids\n",
    "\n",
    "            outputs = layer(inputs, **kwargs)\n",
    "\n",
    "            # `outputs` will be the inputs to the next layer.\n",
    "            inputs = outputs\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def build_dense_dropout_model(n_layers, width, dropout, dense_kwargs,\n",
    "                              name=None):\n",
    "    \"\"\"Build a Sequential model composed of stacked Dense and Dropout blocks.\n",
    "\n",
    "    Calling with n_layers=1 corresponds to the output:\n",
    "    Sequential([Dense(width), Dropout(dropout)])\n",
    "\n",
    "    Args:\n",
    "        n_layers: Number of layers to stack\n",
    "        width: Width of the layers\n",
    "        dropout: Dropout probability\n",
    "        dense_kwargs: Additionaly kwargs for the Dense class\n",
    "\n",
    "    Returns:\n",
    "        Sequential model of stacked Dense Dropout layers\n",
    "\n",
    "    \"\"\"\n",
    "    if dropout > 0.:\n",
    "        layers = list(chain(*(\n",
    "            (Dense(width, **dense_kwargs), Dropout(dropout))\n",
    "            for i in range(n_layers)\n",
    "        )))\n",
    "    else:\n",
    "        layers = [Dense(width, **dense_kwargs) for i in range(n_layers)]\n",
    "    return tf.keras.Sequential(layers, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bb06495-06c0-4c21-985f-7551e33c2173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.python.framework.smart_cond import smart_cond\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_time=20000, n_dim=10, **kwargs):\n",
    "        self.max_time = max_time\n",
    "        self.n_dim = n_dim\n",
    "        self._num_timescales = self.n_dim // 2\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_timescales(self):\n",
    "        # This is a bit hacky, but works\n",
    "        timescales = self.max_time ** np.linspace(0, 1, self._num_timescales)\n",
    "        return timescales\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.timescales = self.add_weight(\n",
    "            'timescales',\n",
    "            (self._num_timescales, ),\n",
    "            trainable=False,\n",
    "            initializer=tf.keras.initializers.Constant(self.get_timescales())\n",
    "        )\n",
    "\n",
    "    def __call__(self, times):\n",
    "        scaled_time = times / self.timescales[None, None, :]\n",
    "        signal = tf.concat(\n",
    "            [\n",
    "                tf.sin(scaled_time),\n",
    "                tf.cos(scaled_time)\n",
    "            ],\n",
    "            axis=-1)\n",
    "        return signal\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], self.n_dim)\n",
    "\n",
    "\n",
    "class CumulativeSetAttentionLayer(tf.keras.layers.Layer):\n",
    "    dense_options = {\n",
    "        'activation': 'relu',\n",
    "        'kernel_initializer': 'he_uniform'\n",
    "    }\n",
    "    def __init__(self, n_layers=2, width=128, latent_width=128,\n",
    "                 aggregation_function='mean',\n",
    "                 dot_prod_dim=64, n_heads=4, attn_dropout=0.3):\n",
    "        super().__init__()\n",
    "        assert aggregation_function == 'mean'\n",
    "        self.width = width\n",
    "        self.dot_prod_dim = dot_prod_dim\n",
    "        self.attn_dropout = attn_dropout\n",
    "        self.n_heads = n_heads\n",
    "        self.psi = build_dense_dropout_model(\n",
    "            n_layers, width, 0., self.dense_options)\n",
    "        self.psi.add(Dense(latent_width, **self.dense_options))\n",
    "        self.rho = Dense(latent_width, **self.dense_options)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.psi.build(input_shape)\n",
    "        encoded_shape = self.psi.compute_output_shape(input_shape)\n",
    "        self.rho.build(encoded_shape)\n",
    "        self.W_k = self.add_weight(\n",
    "            'W_k',\n",
    "            (encoded_shape[-1] + input_shape[-1], self.dot_prod_dim*self.n_heads),\n",
    "            initializer='he_uniform'\n",
    "        )\n",
    "        self.W_q = self.add_weight(\n",
    "            'W_q', (self.n_heads, self.dot_prod_dim),\n",
    "            initializer=tf.keras.initializers.Zeros()\n",
    "        )\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.n_heads)\n",
    "\n",
    "    def call(self, inputs, segment_ids, training=None):\n",
    "        if training is None:\n",
    "            training = tf.keras.backend.learning_phase()\n",
    "\n",
    "        encoded = self.psi(inputs)\n",
    "\n",
    "        # cumulative mean aggregation\n",
    "        agg = cumulative_segment_mean(encoded, segment_ids)\n",
    "        agg = self.rho(agg)\n",
    "\n",
    "        combined = tf.concat([inputs, agg], axis=-1)\n",
    "        keys = tf.matmul(combined, self.W_k)\n",
    "        keys = tf.stack(tf.split(keys, self.n_heads, -1), 1)\n",
    "        keys = tf.expand_dims(keys, axis=2)\n",
    "        # should have shape (el, heads, 1, dot_prod_dim)\n",
    "        queries = tf.expand_dims(tf.expand_dims(self.W_q, -1), 0)\n",
    "        # should have shape (1, heads, dot_prod_dim, 1)\n",
    "        preattn = tf.matmul(keys, queries) / tf.sqrt(float(self.dot_prod_dim))\n",
    "        preattn = tf.squeeze(tf.squeeze(preattn, -1), -1)\n",
    "        return preattn\n",
    "\n",
    "\n",
    "class SetAttentionLayer(tf.keras.layers.Layer):\n",
    "    dense_options = {\n",
    "        'activation': 'relu',\n",
    "        'kernel_initializer': 'he_uniform'\n",
    "    }\n",
    "    def __init__(self, n_layers=2, width=128, latent_width=128,\n",
    "                 aggregation_function='mean',\n",
    "                 dot_prod_dim=64, n_heads=4, attn_dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "        self.dot_prod_dim = dot_prod_dim\n",
    "        self.attn_dropout = attn_dropout\n",
    "        self.n_heads = n_heads\n",
    "        self.psi = build_dense_dropout_model(\n",
    "            n_layers, width, 0., self.dense_options)\n",
    "        self.psi.add(Dense(latent_width, **self.dense_options))\n",
    "        self.psi_aggregation = SegmentAggregation(aggregation_function)\n",
    "        self.rho = Dense(latent_width, **self.dense_options)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.psi.build(input_shape)\n",
    "        encoded_shape = self.psi.compute_output_shape(input_shape)\n",
    "        agg_shape = self.psi_aggregation.compute_output_shape(encoded_shape)\n",
    "        self.rho.build(agg_shape)\n",
    "        self.W_k = self.add_weight(\n",
    "            'W_k',\n",
    "            (encoded_shape[-1] + input_shape[-1], self.dot_prod_dim*self.n_heads),\n",
    "            initializer='he_uniform'\n",
    "        )\n",
    "        self.W_q = self.add_weight(\n",
    "            'W_q', (self.n_heads, self.dot_prod_dim),\n",
    "            initializer=tf.keras.initializers.Zeros()\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, segment_ids, lengths, training=None):\n",
    "        if training is None:\n",
    "            training = tf.keras.backend.learning_phase()\n",
    "\n",
    "        def dropout_attn(input_tensor):\n",
    "            if self.attn_dropout > 0:\n",
    "                mask = (\n",
    "                    tf.random.uniform(\n",
    "                        tf.shape(input_tensor)[:-1]\n",
    "                    ) < self.attn_dropout)\n",
    "                return (\n",
    "                    input_tensor\n",
    "                    + tf.expand_dims(tf.cast(mask, tf.float32), -1) * -1e9\n",
    "                )\n",
    "            else:\n",
    "                return tf.identity(input_tensor)\n",
    "\n",
    "        encoded = self.psi(inputs)\n",
    "        agg = self.psi_aggregation(encoded, segment_ids)\n",
    "        agg = self.rho(agg)\n",
    "        agg_scattered = tf.gather_nd(agg, tf.expand_dims(segment_ids, -1))\n",
    "        combined = tf.concat([inputs, agg_scattered], axis=-1)\n",
    "        keys = tf.matmul(combined, self.W_k)\n",
    "        keys = tf.stack(tf.split(keys, self.n_heads, -1), 1)\n",
    "        keys = tf.expand_dims(keys, axis=2)\n",
    "        # should have shape (el, heads, 1, dot_prod_dim)\n",
    "        queries = tf.expand_dims(tf.expand_dims(self.W_q, -1), 0)\n",
    "        # should have shape (1, heads, dot_prod_dim, 1)\n",
    "        preattn = tf.matmul(keys, queries) / tf.sqrt(float(self.dot_prod_dim))\n",
    "        preattn = tf.squeeze(preattn, -1)\n",
    "        preattn = smart_cond(\n",
    "            training,\n",
    "            lambda: dropout_attn(preattn),\n",
    "            lambda: tf.identity(preattn)\n",
    "        )\n",
    "\n",
    "        per_head_preattn = tf.unstack(preattn, axis=1)\n",
    "        attentions = []\n",
    "        for pre_attn in per_head_preattn:\n",
    "            attentions.append(segment_softmax(pre_attn, segment_ids))\n",
    "        return attentions\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return list(chain(input_shape[:-1], (self.n_heads, )))\n",
    "\n",
    "\n",
    "class IdentityLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        return input_shapes\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return inputs\n",
    "\n",
    "\n",
    "class DeepSetAttentionModel(tf.keras.Model):\n",
    "    dense_options = {\n",
    "        'activation': 'relu',\n",
    "        'kernel_initializer': 'he_uniform'\n",
    "    }\n",
    "\n",
    "    def __init__(self, output_activation, output_dims, n_phi_layers, phi_width,\n",
    "                 n_psi_layers, psi_width, psi_latent_width, dot_prod_dim,\n",
    "                 n_heads, attn_dropout, latent_width, phi_dropout,\n",
    "                 n_rho_layers, rho_width, rho_dropout, max_timescale,\n",
    "                 n_positional_dims):\n",
    "        self._config = {\n",
    "            name: val for name, val in locals().items()\n",
    "            if name not in ['self', '__class__']\n",
    "        }\n",
    "        super().__init__()\n",
    "        self.phi_width = phi_width\n",
    "        self.to_segments = PaddedToSegments()\n",
    "        # If we set n_positional_dims to 0, skip the positional encoding\n",
    "        self.positional_encoding = (\n",
    "            PositionalEncoding(max_timescale, n_positional_dims)\n",
    "            if n_positional_dims != 0\n",
    "            else IdentityLayer()\n",
    "        )\n",
    "        # We need the input dimensionality in order to determine the size of\n",
    "        # the embedding for the demographics.\n",
    "        self.demo_encoder = None\n",
    "        if isinstance(output_dims, Sequence):\n",
    "            # We have an online prediction scenario\n",
    "            assert output_dims[0] is None\n",
    "            self.return_sequences = True\n",
    "            output_dims = output_dims[1]\n",
    "        else:\n",
    "            self.return_sequences = False\n",
    "\n",
    "        # Build phi architecture\n",
    "        self.phi = build_dense_dropout_model(\n",
    "            n_phi_layers, phi_width, phi_dropout, self.dense_options)\n",
    "        self.phi.add(Dense(latent_width, **self.dense_options))\n",
    "        self.latent_width = latent_width\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        if self.return_sequences:\n",
    "            self.attention = CumulativeSetAttentionLayer(\n",
    "                n_psi_layers, psi_width, psi_latent_width,\n",
    "                dot_prod_dim=dot_prod_dim, n_heads=n_heads,\n",
    "                attn_dropout=attn_dropout\n",
    "            )\n",
    "        else:\n",
    "            self.attention = SetAttentionLayer(\n",
    "                n_psi_layers, psi_width, psi_latent_width,\n",
    "                dot_prod_dim=dot_prod_dim, n_heads=n_heads,\n",
    "                attn_dropout=attn_dropout\n",
    "            )\n",
    "\n",
    "        self.aggregation = SegmentAggregation(\n",
    "            aggregation_fn='sum',\n",
    "            cumulative=self.return_sequences\n",
    "        )\n",
    "\n",
    "        # Build rho architecture\n",
    "        self.rho = build_dense_dropout_model(\n",
    "            n_rho_layers, rho_width, rho_dropout, self.dense_options)\n",
    "        self.rho.add(Dense(output_dims, activation=output_activation))\n",
    "        self._n_modalities = None\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        if self.return_sequences:\n",
    "            demo, times, values, measurements, lengths, inverse_timepoints, pred_lengths = input_shapes\n",
    "        else:\n",
    "            demo, times, values, measurements, lengths = input_shapes\n",
    "        self.positional_encoding.build(times)\n",
    "        transformed_times = (\n",
    "            self.positional_encoding.compute_output_shape(times))\n",
    "        mod_shape = self._n_modalities\n",
    "        phi_input_dim = transformed_times[-1] + values[-1] + mod_shape\n",
    "        self.demo_encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(self.phi_width, activation='relu'),\n",
    "                tf.keras.layers.Dense(phi_input_dim)\n",
    "            ],\n",
    "            name='demo_encoder'\n",
    "        )\n",
    "        self.demo_encoder.build(demo)\n",
    "        if self.return_sequences:\n",
    "            phi_input = (None, phi_input_dim)\n",
    "            self.phi.build(phi_input)\n",
    "            phi_output = self.phi.compute_output_shape(phi_input)\n",
    "            self.attention.build(phi_input)\n",
    "            attention_output = self.attention.compute_output_shape(phi_input)\n",
    "            aggregated_output = [\n",
    "                phi_output[0], phi_output[1] * attention_output[1]]\n",
    "            self.rho.build(aggregated_output)\n",
    "        else:\n",
    "            phi_input = (None, phi_input_dim)\n",
    "            self.phi.build(phi_input)\n",
    "            phi_output = self.phi.compute_output_shape(phi_input)\n",
    "            self.attention.build(phi_input)\n",
    "            attention_output = self.attention.compute_output_shape(phi_input)\n",
    "            aggregated_output = self.aggregation.compute_output_shape(\n",
    "                [phi_output[0], phi_output[1] * attention_output[1]])\n",
    "            self.rho.build(aggregated_output)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.return_sequences:\n",
    "            demo, times, values, measurements, lengths, elem_per_tp, pred_lengths = inputs\n",
    "            if len(pred_lengths.get_shape()) == 2:\n",
    "                pred_lengths = tf.squeeze(pred_lengths, -1)\n",
    "        else:\n",
    "            demo, times, values, measurements, lengths = inputs\n",
    "        transformed_times = self.positional_encoding(times)\n",
    "\n",
    "        # Transform modalities\n",
    "        transformed_measurements = tf.one_hot(\n",
    "            measurements, self._n_modalities, dtype=tf.float32)\n",
    "\n",
    "        combined_values = tf.concat(\n",
    "            (\n",
    "                transformed_times,\n",
    "                values,\n",
    "                transformed_measurements\n",
    "            ),\n",
    "            axis=-1\n",
    "        )\n",
    "        demo_encoded = self.demo_encoder(demo)\n",
    "        combined_with_demo = tf.concat(\n",
    "            [tf.expand_dims(demo_encoded, 1), combined_values], axis=1)\n",
    "\n",
    "        # Somehow eager execution and graph mode behave differently.\n",
    "        # In graph mode lengths has an additional dimension\n",
    "        if len(lengths.get_shape()) == 2:\n",
    "            lengths = tf.squeeze(lengths, -1)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            # We additionally have the encoded demographics as a set element\n",
    "            mask = tf.sequence_mask(lengths+1, name='mask')\n",
    "\n",
    "            collected_values, segment_ids = self.to_segments(\n",
    "                combined_with_demo, mask)\n",
    "\n",
    "            preattentions = self.attention(collected_values, segment_ids)\n",
    "            encoded = self.phi(collected_values)\n",
    "            agg = cumulative_softmax_weighting(\n",
    "                encoded, preattentions, segment_ids)\n",
    "            # Remove heads dimension\n",
    "            agg = tf.reshape(\n",
    "                agg,\n",
    "                tf.stack([tf.shape(agg)[0], tf.constant(-1)], axis=0)\n",
    "            )\n",
    "\n",
    "            predictions_mask = tf.sequence_mask(pred_lengths)\n",
    "            gathered_time_indices, batch_indices = self.to_segments(\n",
    "                elem_per_tp, predictions_mask)\n",
    "\n",
    "            # Compute index of the last observation associated with the\n",
    "            # provided time.\n",
    "            prediction_indices = tf.math.cumsum(gathered_time_indices)\n",
    "            # Add an offset for each instance to account for demographics. This\n",
    "            # offset decreases for each later index in the batch. Thus we can\n",
    "            # use the batch indices.\n",
    "            prediction_indices += batch_indices\n",
    "\n",
    "            gathered_embeddings = tf.gather_nd(\n",
    "                agg, prediction_indices[:, None])\n",
    "            # Lost shape information\n",
    "            gathered_embeddings.set_shape([None, None])\n",
    "            output = self.rho(gathered_embeddings)\n",
    "\n",
    "            valid_predictions = tf.cast(tf.where(predictions_mask), tf.int32)\n",
    "\n",
    "            output = tf.scatter_nd(\n",
    "                valid_predictions,\n",
    "                output,\n",
    "                tf.concat(\n",
    "                    [tf.shape(predictions_mask), tf.shape(output)[-1:]],\n",
    "                    axis=0\n",
    "                )\n",
    "            )\n",
    "            # tf.print(tf.shape(output), tf.shape(mask))\n",
    "            output._keras_mask = predictions_mask\n",
    "            return output\n",
    "        else:\n",
    "            # We additionally have the encoded demographics as a set element\n",
    "            mask = tf.sequence_mask(lengths+1, name='mask')\n",
    "\n",
    "            collected_values, segment_ids = self.to_segments(\n",
    "                combined_with_demo, mask)\n",
    "\n",
    "            encoded = self.phi(collected_values)\n",
    "            attentions = self.attention(collected_values, segment_ids, lengths)\n",
    "\n",
    "            weighted_values = []\n",
    "            for attention in attentions:\n",
    "                weighted_values.append(encoded * attention)\n",
    "\n",
    "            aggregated_values = self.aggregation(\n",
    "                tf.concat(weighted_values, axis=-1), segment_ids)\n",
    "            return self.rho(aggregated_values)\n",
    "\n",
    "    def get_attentions(self, inputs):\n",
    "        demo, times, values, measurements, lengths = inputs\n",
    "        transformed_times = self.positional_encoding(times)\n",
    "\n",
    "        # Transform modalities\n",
    "        if self._n_modalities > 100:\n",
    "            # Use an embedding instead of one hot encoding when we have a very\n",
    "            # high number of modalities\n",
    "            transformed_measurements = self.modality_embedding(measurements)\n",
    "        else:\n",
    "            transformed_measurements = tf.one_hot(\n",
    "                measurements, self._n_modalities, dtype=tf.float32)\n",
    "\n",
    "        combined_values = tf.concat(\n",
    "            (\n",
    "                transformed_times,\n",
    "                values,\n",
    "                transformed_measurements\n",
    "            ),\n",
    "            axis=-1\n",
    "        )\n",
    "        demo_encoded = self.demo_encoder(demo)\n",
    "        combined_with_demo = tf.concat(\n",
    "            [tf.expand_dims(demo_encoded, 1), combined_values], axis=1)\n",
    "        # Somehow eager execution and graph mode behave differently.\n",
    "        # In graph mode legths has an additional dimension\n",
    "        if len(lengths.get_shape()) == 2:\n",
    "            lengths = tf.squeeze(lengths, -1)\n",
    "\n",
    "        # We additionally have the encoded demographics as a set element\n",
    "        mask = tf.sequence_mask(lengths+1, name='mask')\n",
    "        valid_observations = tf.cast(tf.where(mask), tf.int32)\n",
    "        out_shape = tf.concat(\n",
    "            [\n",
    "                tf.shape(combined_with_demo)[:-1],\n",
    "                tf.constant([1])\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        collected_values, segment_ids = self.to_segments(combined_with_demo, mask)\n",
    "\n",
    "        attentions = self.attention(collected_values, segment_ids, lengths)\n",
    "\n",
    "        demo_attentions = []\n",
    "        ts_attentions = []\n",
    "\n",
    "        for attention in attentions:\n",
    "            dist_attention = tf.scatter_nd(\n",
    "                    valid_observations, attention, out_shape)\n",
    "            demo_attentions.append(dist_attention[:, 0])\n",
    "            ts_attentions.append(dist_attention[:, 1:])\n",
    "        return demo_attentions, ts_attentions\n",
    "\n",
    "    def _evtl_create_embedding_layer(self):\n",
    "        if self._n_modalities > 100 and not hasattr(self, 'modality_embedding'):\n",
    "            self.modality_embedding = tf.keras.layers.Embedding(\n",
    "                self._n_modalities, 64)\n",
    "\n",
    "    @classmethod\n",
    "    def get_hyperparameters(cls):\n",
    "        import tensorboard.plugins.hparams.api as hp\n",
    "        from ..training_utils import HParamWithDefault\n",
    "        return [\n",
    "            HParamWithDefault(\n",
    "                'n_phi_layers', hp.Discrete([1, 2, 3, 4, 5]), default=3),\n",
    "            HParamWithDefault(\n",
    "                'phi_width',\n",
    "                hp.Discrete([16, 32, 64, 128, 256, 512]),\n",
    "                default=32\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'phi_dropout',\n",
    "                hp.Discrete([0.0, 0.1, 0.2, 0.3]),\n",
    "                default=0.\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'n_psi_layers',\n",
    "                hp.Discrete([2]),\n",
    "                default=2\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'psi_width',\n",
    "                hp.Discrete([64]),\n",
    "                default=64\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'psi_latent_width',\n",
    "                hp.Discrete([128]),\n",
    "                default=128\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'dot_prod_dim',\n",
    "                hp.Discrete([128]),\n",
    "                default=128\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'n_heads',\n",
    "                hp.Discrete([4]),\n",
    "                default=4\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'attn_dropout',\n",
    "                hp.Discrete([0.0, 0.1, 0.25, 0.5]),\n",
    "                default=0.1\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'latent_width',\n",
    "                hp.Discrete([32, 64, 128, 256, 512, 1024, 2048]),\n",
    "                default=128\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'n_rho_layers', hp.Discrete([1, 2, 3, 4, 5]), default=3),\n",
    "            HParamWithDefault(\n",
    "                'rho_width',\n",
    "                hp.Discrete([16, 32, 64, 128, 256, 512]),\n",
    "                default=32\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'rho_dropout',\n",
    "                hp.Discrete([0.0, 0.1, 0.2, 0.3]),\n",
    "                default=0.\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'max_timescale',\n",
    "                hp.Discrete([10., 100., 1000.]),\n",
    "                default=100.\n",
    "            ),\n",
    "            HParamWithDefault(\n",
    "                'n_positional_dims',\n",
    "                hp.Discrete([4, 8, 16]),\n",
    "                default=4\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def from_hyperparameter_dict(cls, task, hparams):\n",
    "        return cls(\n",
    "            output_activation=task.output_activation,\n",
    "            output_dims=task.n_outputs,\n",
    "            n_phi_layers=hparams['n_phi_layers'],\n",
    "            phi_width=hparams['phi_width'],\n",
    "            n_psi_layers=hparams['n_psi_layers'],\n",
    "            psi_width=hparams['psi_width'],\n",
    "            psi_latent_width=hparams['psi_latent_width'],\n",
    "            dot_prod_dim=hparams['dot_prod_dim'],\n",
    "            n_heads=hparams['n_heads'],\n",
    "            attn_dropout=hparams['attn_dropout'],\n",
    "            latent_width=hparams['latent_width'],\n",
    "            phi_dropout=hparams['phi_dropout'],\n",
    "            n_rho_layers=hparams['n_rho_layers'],\n",
    "            rho_width=hparams['rho_width'],\n",
    "            rho_dropout=hparams['rho_dropout'],\n",
    "            max_timescale=hparams['max_timescale'],\n",
    "            n_positional_dims=hparams['n_positional_dims']\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "    def get_config(self):\n",
    "        return self._config\n",
    "\n",
    "    def data_preprocessing_fn(self):\n",
    "        def flatten_unaligned_measurements(ts, labels):\n",
    "            # Ignore demographics for now\n",
    "            demo, X, Y, measurements, lengths = ts\n",
    "            if self._n_modalities is None:\n",
    "                self._n_modalities = int(measurements.get_shape()[-1])\n",
    "            X = tf.expand_dims(X, -1)\n",
    "            measurement_positions = tf.cast(tf.where(measurements), tf.int32)\n",
    "            X_indices = measurement_positions[:, 0]\n",
    "            Y_indices = measurement_positions[:, 1]\n",
    "\n",
    "            gathered_X = tf.gather(X, X_indices)\n",
    "            gathered_Y = tf.gather_nd(Y, measurement_positions)\n",
    "            gathered_Y = tf.expand_dims(gathered_Y, axis=-1)\n",
    "\n",
    "            length = tf.shape(X_indices)[0]\n",
    "            if self.return_sequences:\n",
    "                # We need to know now many prediction values each instance\n",
    "                # should have when doing online prediction\n",
    "                prediction_length = tf.shape(labels)[0]\n",
    "                counts = tf.reduce_sum(tf.cast(measurements, tf.int64), axis=1)\n",
    "                return (demo, gathered_X, gathered_Y, Y_indices, length, counts, prediction_length), labels\n",
    "            else:\n",
    "                return (demo, gathered_X, gathered_Y, Y_indices, length), labels\n",
    "\n",
    "        return flatten_unaligned_measurements\n",
    "\n",
    "    @classmethod\n",
    "    def get_default(cls, task):\n",
    "        hyperparams = cls.get_hyperparameters()\n",
    "        return cls.from_hyperparameter_dict(\n",
    "            task,\n",
    "            {\n",
    "                h.name: h._default for h in hyperparams\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class DeepSetAttentionNoPosModel(DeepSetAttentionModel):\n",
    "    def __init__(self, output_activation, output_dims, **kwargs):\n",
    "        super().__init__(output_activation, output_dims, **kwargs,\n",
    "                         max_timescale=0,\n",
    "                         n_positional_dims=0)\n",
    "\n",
    "    @classmethod\n",
    "    def get_hyperparameters(cls):\n",
    "        parent_hyperparameters = super().get_hyperparameters()\n",
    "        return [\n",
    "            hp for hp in parent_hyperparameters\n",
    "            if hp.name not in ['max_timescale', 'n_positional_dims']\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def from_hyperparameter_dict(cls, task, hparams):\n",
    "        return cls(\n",
    "            output_activation=task.output_activation,\n",
    "            output_dims=task.n_outputs,\n",
    "            n_phi_layers=hparams['n_phi_layers'],\n",
    "            phi_width=hparams['phi_width'],\n",
    "            n_psi_layers=hparams['n_psi_layers'],\n",
    "            psi_width=hparams['psi_width'],\n",
    "            psi_latent_width=hparams['psi_latent_width'],\n",
    "            dot_prod_dim=hparams['dot_prod_dim'],\n",
    "            n_heads=hparams['n_heads'],\n",
    "            attn_dropout=hparams['attn_dropout'],\n",
    "            latent_width=hparams['latent_width'],\n",
    "            phi_dropout=hparams['phi_dropout'],\n",
    "            n_rho_layers=hparams['n_rho_layers'],\n",
    "            rho_width=hparams['rho_width'],\n",
    "            rho_dropout=hparams['rho_dropout'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b699c30-fa39-4c3e-9528-95339edf9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSetAttentionModel(\n",
    "    output_activation='sigmoid', \n",
    "    output_dims=1, \n",
    "    n_phi_layers=4, \n",
    "    phi_width=128,\n",
    "    phi_dropout=0.2,\n",
    "    n_psi_layers=2, \n",
    "    psi_width=64, \n",
    "    psi_latent_width=128, \n",
    "    dot_prod_dim=128,      \n",
    "    n_heads=4, \n",
    "    attn_dropout=0.5, \n",
    "    latent_width=32, \n",
    "    n_rho_layers=2, \n",
    "    rho_width=512, \n",
    "    rho_dropout=0.0, \n",
    "    max_timescale=100.0,\n",
    "    n_positional_dims=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2553b77-8bc0-4d08-a888-b8c6cfbf805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer=optim,\n",
    "    loss='binary_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ca49f-121b-42fa-bc42-7c62dc32e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fyp_strats_37] *",
   "language": "python",
   "name": "conda-env-.conda-fyp_strats_37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
